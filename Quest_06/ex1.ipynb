{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ec45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "# Downloading the dataset\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "\n",
    "# Loading the dataset\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f018c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40928</th>\n",
       "      <td>Minors can't opt out of Aadhaar after turning ...</td>\n",
       "      <td>Minors cannot opt out of Aadhaar after turning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27334</th>\n",
       "      <td>Japan PM cancels Iran visit amid US pressure: ...</td>\n",
       "      <td>Japanese PM Shinzo Abe has cancelled his visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>Google India announces summer camp for 100 kid...</td>\n",
       "      <td>Google India has announced a contest for kids,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45269</th>\n",
       "      <td>Tribunal bars 64 entities from selling assets ...</td>\n",
       "      <td>The National Company Law Tribunal has passed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52399</th>\n",
       "      <td>Tanzanian probe claims Airtel unit was privati...</td>\n",
       "      <td>A Tanzanian probe has claimed that the local u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>He is one of best CFOs in India: Murthy on Ran...</td>\n",
       "      <td>Reacting to Infosys CFO Ranganath's resignatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60558</th>\n",
       "      <td>10 arrested for Mumbai University examination ...</td>\n",
       "      <td>The Amboli police on Friday arrested 10 people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87607</th>\n",
       "      <td>19-year-old wins Ã¢ÂÂ¹1 crore after scoring l...</td>\n",
       "      <td>Nineteen-year-old professional gamer Corentin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87462</th>\n",
       "      <td>Floods, landslides kill 91 in Sri Lanka</td>\n",
       "      <td>Floods and landslides in Sri Lanka have killed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84662</th>\n",
       "      <td>Role is role, doesn't matter if it's big or sm...</td>\n",
       "      <td>Nawazuddin Siddiqui has said a role is a role ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "40928  Minors can't opt out of Aadhaar after turning ...   \n",
       "27334  Japan PM cancels Iran visit amid US pressure: ...   \n",
       "29179  Google India announces summer camp for 100 kid...   \n",
       "45269  Tribunal bars 64 entities from selling assets ...   \n",
       "52399  Tanzanian probe claims Airtel unit was privati...   \n",
       "21050  He is one of best CFOs in India: Murthy on Ran...   \n",
       "60558  10 arrested for Mumbai University examination ...   \n",
       "87607  19-year-old wins Ã¢ÂÂ¹1 crore after scoring l...   \n",
       "87462            Floods, landslides kill 91 in Sri Lanka   \n",
       "84662  Role is role, doesn't matter if it's big or sm...   \n",
       "\n",
       "                                                    text  \n",
       "40928  Minors cannot opt out of Aadhaar after turning...  \n",
       "27334  Japanese PM Shinzo Abe has cancelled his visit...  \n",
       "29179  Google India has announced a contest for kids,...  \n",
       "45269  The National Company Law Tribunal has passed a...  \n",
       "52399  A Tanzanian probe has claimed that the local u...  \n",
       "21050  Reacting to Infosys CFO Ranganath's resignatio...  \n",
       "60558  The Amboli police on Friday arrested 10 people...  \n",
       "87607  Nineteen-year-old professional gamer Corentin ...  \n",
       "87462  Floods and landslides in Sri Lanka have killed...  \n",
       "84662  Nawazuddin Siddiqui has said a role is a role ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2af79",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    " 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ad884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d41d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5285f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2172ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf17e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef44489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf2f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2172f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"]=data[\"text\"].apply(lambda x: preprocess_sentence(x) )\n",
    "data[\"headlines\"]=data[\"headlines\"].apply(lambda x: preprocess_sentence(x,False) )\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')\n",
    "print(data.shape)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 데이터 전처리\n",
    "clean_text = []\n",
    "for sentence in data[\"text\"]:\n",
    "clean_text.append(preprocess_sentence(sentence, remove_stopwords=True))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])\n",
    "\n",
    "# headlines 데이터 전처리 단 요약데이터는 짧으므로 불용어 제거 안함 remove_stopwords=False\n",
    "clean_headlines = []\n",
    "for sentence in data[\"headlines\"]:\n",
    "clean_headlines.append(preprocess_sentence(sentence, remove_stopwords=False))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('해드라인의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('해드라인의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('해드라인의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfc3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len =40 \n",
    "headlines_max_len = 8\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18db482",
   "metadata": {},
   "outputs": [],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bcc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, calculate the length of each text and summary\n",
    "data['text_len'] = data['text'].apply(lambda x: len(x.split()))\n",
    "data['headlines_len'] = data['headlines'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Then, filter out rows where text length or summary length exceeds the maximum\n",
    "data = data[(data['text_len'] <= text_max_len) & (data['headlines_len'] <= headlines_max_len)]\n",
    "\n",
    "# Optionally, you can drop the length columns if they are no longer needed\n",
    "data = data.drop(['text_len', 'headlines_len'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3780022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677061a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb79dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f91d81ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 65532\n",
      "훈련 레이블의 개수 : 65532\n",
      "테스트 데이터의 개수 : 16382\n",
      "테스트 레이블의 개수 : 16382\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14f19800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95597d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 63018\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 43071\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 19947\n",
      "단어 집합에서 희귀 단어의 비율: 68.3471389126916\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.9088011489059915\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3193ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2609, 2248, 17521, 608, 33, 104, 538, 1762, 12, 2023, 156, 1295, 1177, 405, 104, 2235, 2681, 160, 1212, 563, 162, 104, 826, 9490, 1388, 1212, 17521, 286, 2812, 160, 139, 3042, 139, 376, 367, 1022], [213, 11917, 275, 575, 973, 7653, 293, 7799, 724, 572, 9127, 13724, 3844, 646, 332, 12, 1812, 8392, 1711, 6189, 25, 78, 13724, 5243, 1317, 3737, 2652, 682, 7654, 1711, 682, 232, 724, 6704, 293, 9739, 1711, 9979, 8392, 3578], [7655, 516, 424, 1482, 230, 820, 36, 2638, 10852, 4601, 4721, 9980, 4722, 3447, 2957, 10254, 845, 9491, 3765, 2669, 272, 800, 637, 1324, 1521, 7943, 4172, 1889, 845, 12722, 18657, 3765, 8095]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b526d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6645cc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b00b5f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 27615\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 18342\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9273\n",
      "단어 집합에서 희귀 단어의 비율: 66.42042368278109\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.8050584215894245\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cab3a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 913, 1348, 70, 528, 89, 332, 1776], [1, 271, 2837, 4134, 1161, 6739], [1, 620, 1590, 212, 1409, 455, 156], [1, 176, 8455, 2418, 3337, 145, 2308, 2903, 243], [1, 166, 1329, 3230, 416, 4135, 179, 4622]]\n",
      "target\n",
      "decoder  [[913, 1348, 70, 528, 89, 332, 1776, 2], [271, 2837, 4134, 1161, 6739, 2], [620, 1590, 212, 1409, 455, 156, 2], [176, 8455, 2418, 3337, 145, 2308, 2903, 243, 2], [166, 1329, 3230, 416, 4135, 179, 4622, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 10000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ced8ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 1\n",
      "훈련 데이터의 개수 : 65531\n",
      "훈련 레이블의 개수 : 65531\n",
      "테스트 데이터의 개수 : 16381\n",
      "테스트 레이블의 개수 : 16381\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b1c4987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fcb95",
   "metadata": {},
   "source": [
    "## Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7848080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Encoder configuration\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# Encoder's Embedding layer\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# Encoder's LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder's LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder's LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=False, return_state=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Note: The last LSTM layer does not return sequences, \n",
    "# it only returns its final states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0614fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31a4019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10000)  5130000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,809,360\n",
      "Trainable params: 10,809,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "651b8695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 38s 122ms/step - loss: 6.6766 - val_loss: 6.3989\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 31s 121ms/step - loss: 6.3730 - val_loss: 6.1852\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 6.1685 - val_loss: 5.9993\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 5.9632 - val_loss: 5.8343\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 5.7452 - val_loss: 5.6492\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 5.5527 - val_loss: 5.5038\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 5.3838 - val_loss: 5.3681\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 5.2272 - val_loss: 5.2702\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 5.0827 - val_loss: 5.1739\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.9544 - val_loss: 5.0988\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.8371 - val_loss: 5.0216\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.7290 - val_loss: 4.9730\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.6273 - val_loss: 4.9124\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.5260 - val_loss: 4.8612\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 31s 121ms/step - loss: 4.4339 - val_loss: 4.8158\n",
      "Epoch 16/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.3473 - val_loss: 4.7853\n",
      "Epoch 17/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.2632 - val_loss: 4.7575\n",
      "Epoch 18/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.1842 - val_loss: 4.7258\n",
      "Epoch 19/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.1112 - val_loss: 4.7026\n",
      "Epoch 20/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 4.0391 - val_loss: 4.6820\n",
      "Epoch 21/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.9736 - val_loss: 4.6750\n",
      "Epoch 22/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.9088 - val_loss: 4.6636\n",
      "Epoch 23/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.8494 - val_loss: 4.6464\n",
      "Epoch 24/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.7922 - val_loss: 4.6340\n",
      "Epoch 25/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.7346 - val_loss: 4.6252\n",
      "Epoch 26/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.6809 - val_loss: 4.6261\n",
      "Epoch 27/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.6307 - val_loss: 4.6228\n",
      "Epoch 28/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.5814 - val_loss: 4.6174\n",
      "Epoch 29/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.5348 - val_loss: 4.6155\n",
      "Epoch 30/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.4923 - val_loss: 4.6114\n",
      "Epoch 31/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.4467 - val_loss: 4.6136\n",
      "Epoch 32/50\n",
      "256/256 [==============================] - 31s 120ms/step - loss: 3.4078 - val_loss: 4.6185\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53d9c1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994fd47e",
   "metadata": {},
   "source": [
    "## Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4608d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a12d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75442946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ab4b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    print(input_seq.shape)\n",
    "    \n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    print(e_out.shape)\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "    print(target_seq.shape)\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65c9f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != 'sostoken' and i != 'eostoken':  # Adjust indices as per your setup\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fe1366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b7a8b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : two year old boy succumbed injuries hit battery operated vehicle nehru park hyderabad tuesday said police boy accompanied siblings mother relatives playing road near elephant enclosure battery operated vehicle hit police added driver vehicle detained \n",
      "실제 요약 : sostoken year old dies hit vehicle hyderabad zoo \n",
      "(1, 40)\n",
      "(1, 256)\n",
      "(1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:266 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 1 is incompatible with layer model_3: expected shape=(None, 40, 256), found shape=(None, 256)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/2384696985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"원문 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"실제 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"예측 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38/953429854.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# stop_condition이 True가 될 때까지 루프 반복\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msampled_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_index_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3459\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3379\u001b[0m           expand_composites=True)\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:266 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 1 is incompatible with layer model_3: expected shape=(None, 40, 256), found shape=(None, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d23f0",
   "metadata": {},
   "source": [
    "## Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce58009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2ab1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a6df2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96ec7bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e448232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae1eb143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60086608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d311b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
