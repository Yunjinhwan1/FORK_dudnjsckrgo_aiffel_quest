{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca555d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bdae8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "# text , headlines\n",
    "data.sample(10)\n",
    "# data.shape // (98401, 2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e8465",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd8aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "data 중 null 취합 확인\n",
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n",
      "남은 전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "#중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "\n",
    "## 중복확인\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "## null 값 확인 \n",
    "print('data 중 null 취합 확인')\n",
    "print(data.isnull().sum())\n",
    "\n",
    "## text 열 기준 중복제거 \n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "\n",
    "print('남은 전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42452c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정규화와 불용어 제거\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e53eb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "headlines: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 정상적으로 전처리 되는지 테스트 \n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3821241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n",
      "headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "# text 데이터 전처리 \n",
    "clean_text = []\n",
    "for sentence in data[\"text\"]:\n",
    "    clean_text.append(preprocess_sentence(sentence, remove_stopwords=True))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])\n",
    "\n",
    "# headlines 데이터 전처리 단 요약데이터는 짧으므로 불용어 제거 안함 remove_stopwords=False\n",
    "clean_headlines = []\n",
    "for sentence in data[\"headlines\"]:\n",
    "    clean_headlines.append(preprocess_sentence(sentence, remove_stopwords=False))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe5648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# 데이터 이상하게 들어 방지 임시데이터 생성\n",
    "tmp_clean_text = clean_text.copy()\n",
    "tmp_clean_headlines = clean_headlines.copy()\n",
    "# 전처리 후 빈값 데이터가 생겼는지 확인 \n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.isnull().sum()\n",
    "\n",
    "# 생겼다면 제거 \n",
    "#data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca85262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    }
   ],
   "source": [
    "# 길이분포 확인\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35aefacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360 => 98343\n"
     ]
    }
   ],
   "source": [
    "# 적정 최대길이 지정 \n",
    "text_max_len = 50\n",
    "headlines_max_len = 15\n",
    "\n",
    "# data에서 로우를 공백기준으로 자른경우 길이가 최대길이보다 작거나 같은 데이터만 포함\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "\n",
    "print(f'전체 샘플수 : {len(tmp_clean_text)} => {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d52e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 데이터에 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "\n",
    "#Numpy 타입으로 저장\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1782db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정수화 \n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "# 샘플 순서 재정의\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "# 테스트 , 훈련데이터 분리 0.2 를 곱해서 8:2 기준으로 분리\n",
    "n_of_val = int(len(encoder_input)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b254196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78675\n",
      "훈련 레이블의 개수 : 78675\n",
      "테스트 데이터의 개수 : 19668\n",
      "테스트 레이블의 개수 : 19668\n"
     ]
    }
   ],
   "source": [
    "# 분리 데이터 확인 \n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8871fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former australian cricketer mark waugh said prithvi shaw led india world cup victory much like sachin tendulkar first thing notice technique similar sachin tendulkar grip stance plays shots around wicket added\n"
     ]
    }
   ],
   "source": [
    "# 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 변경 \n",
    "print(encoder_input_train[0])\n",
    "# Keras의 토크나이저를 사용\n",
    "# src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "# src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1af963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_train \n",
      "단어 집합(vocabulary)의 크기 : 69560\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47435\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22125\n",
      "단어 집합에서 희귀 단어의 비율: 68.19292696952272\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4964753798189823\n",
      "decoder_input_train \n",
      "단어 집합(vocabulary)의 크기 : 30082\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20569\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9513\n",
      "단어 집합에서 희귀 단어의 비율: 68.37643773685261\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.31702261539031\n"
     ]
    }
   ],
   "source": [
    "# 집합크기 제한전 적정값을 찾기위해 값 추출 함수화 \n",
    "def get_data_index_per(threshold = 7,data = False):\n",
    "    src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "    src_tokenizer.fit_on_texts(data) # 입력된 데이터로부터 단어 집합 생성\n",
    "    threshold = 7\n",
    "    total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in src_tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    \n",
    "print(\"encoder_input_train \")\n",
    "get_data_index_per(7,encoder_input_train)\n",
    "\n",
    "print(\"decoder_input_train \")\n",
    "get_data_index_per(6,decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3681deae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input  [[27, 311, 303, 539, 8827, 1, 6410, 3835, 119, 2, 18, 194, 838, 414, 35, 523, 870, 7, 1294, 839, 4144, 860, 523, 870, 9510, 5427, 2491, 5016, 66, 1070, 4], [1078, 3021, 183, 2113, 2532, 794, 8, 10737, 76, 8692, 18384, 290, 8692, 275, 118, 1720, 15373, 2102, 302, 8692, 208, 8549, 1078, 1, 29, 179, 1078, 300, 1997, 14306, 329, 7, 415, 11562, 866, 2459], [4572, 1381, 182, 1464, 27, 11, 1949, 100, 3654, 48, 1459, 50, 420, 5709, 7686, 1145, 570, 518, 155, 110, 5709, 93, 1451, 2987, 488, 17, 214, 6411, 243, 567, 15, 6, 856, 2881, 3954, 7474, 3500, 495, 1956]]\n",
      "decoder input  [[1, 5655, 2531, 19, 742, 850, 94, 275, 1346, 851, 5404], [1, 652, 3, 2845, 852, 1921, 4012, 4, 266], [1, 1840, 572, 6, 3039, 57, 7, 1124, 290, 4556, 53], [1, 692, 6491, 3899, 3, 676, 398], [1, 335, 3, 3808, 469, 4, 58, 15, 2437, 8163]]\n",
      "decoder target  [[5655, 2531, 19, 742, 850, 94, 275, 1346, 851, 5404, 2], [652, 3, 2845, 852, 1921, 4012, 4, 266, 2], [1840, 572, 6, 3039, 57, 7, 1124, 290, 4556, 53, 2], [692, 6491, 3899, 3, 676, 398, 2], [335, 3, 3808, 469, 4, 58, 15, 2437, 8163, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 제외 집합크기 약 20000 , 9500 으로 텍스트를 정수로 변환작업 \n",
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print('encoder input ',encoder_input_train[:3])\n",
    "\n",
    "tar_vocab = 9500\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('decoder input ',decoder_input_train[:5])\n",
    "print('decoder target ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bedb7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78674\n",
      "훈련 레이블의 개수 : 78674\n",
      "테스트 데이터의 개수 : 19668\n",
      "테스트 레이블의 개수 : 19668\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 과정에서 공백이되어버린 sos , eos 가 남아있기때문에 1 값을 찾아 삭제 \n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0158f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  27  311  303 ...    0    0    0]\n",
      " [1078 3021  183 ...    0    0    0]\n",
      " [4572 1381  182 ...    0    0    0]\n",
      " ...\n",
      " [ 164   20   62 ...    0    0    0]\n",
      " [ 259   47   14 ...    0    0    0]\n",
      " [ 224  805 5291 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 길이맞추기위해서 post 기준으로 padding 추가 \n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print(encoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11534a55",
   "metadata": {},
   "source": [
    "### Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21113af9",
   "metadata": {},
   "source": [
    "인코딩 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308957a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a945963",
   "metadata": {},
   "source": [
    "디코딩 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d0ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b99ae",
   "metadata": {},
   "source": [
    "출력층 ( 어텐션 메커니즘 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d78a038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1216000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9500)   4873500     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,488,860\n",
      "Trainable params: 10,488,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "# decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "# decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "# 모델 정의\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "# model.summary()\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_output3])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76ec05",
   "metadata": {},
   "source": [
    "모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6054b968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 44s 120ms/step - loss: 4.5237 - val_loss: 4.1907\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 4.0358 - val_loss: 3.8840\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 36s 116ms/step - loss: 3.7464 - val_loss: 3.6340\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.5290 - val_loss: 3.4740\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.3671 - val_loss: 3.3717\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.2304 - val_loss: 3.2878\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.1130 - val_loss: 3.2204\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.0121 - val_loss: 3.1490\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.9242 - val_loss: 3.1066\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.8455 - val_loss: 3.0791\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.7727 - val_loss: 3.0450\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.7063 - val_loss: 3.0113\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.6454 - val_loss: 2.9902\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.5937 - val_loss: 2.9777\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.5432 - val_loss: 2.9625\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.4965 - val_loss: 2.9557\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.4535 - val_loss: 2.9404\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.4108 - val_loss: 2.9396\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.3724 - val_loss: 2.9288\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.3352 - val_loss: 2.9174\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.3037 - val_loss: 2.9170\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.2716 - val_loss: 2.9184\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.2400 - val_loss: 2.9149\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.2094 - val_loss: 2.9067\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.1810 - val_loss: 2.9122\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.1543 - val_loss: 2.9151\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f6162",
   "metadata": {},
   "source": [
    "훈련된 모델 로스값 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43671da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82607c6",
   "metadata": {},
   "source": [
    "### Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc36cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제데이터 복원을위한 데이터셋 \n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output3, state_h3, state_c3])\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf90de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378eb40",
   "metadata": {},
   "source": [
    "단어 시퀀스를 완성을 위한 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ade0d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26c71e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i == 2): # End token\n",
    "            break\n",
    "        if (i!=0 and i != 1): # Exclude padding and start token\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242bee2",
   "metadata": {},
   "source": [
    "데이터 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca331501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : actor ajay devgn took social media share first look upcoming film baadshaho caption alongside poster read film also stars emraan hashmi ileana cruz vidyut jammwal esha gupta directed milan action thriller scheduled release september \n",
      "실제 요약 : ajay devgn shares his first look from baadshaho \n",
      "예측 요약 :  ajay devgn shares first look of his st film\n",
      "\n",
      "\n",
      "원문 : vaibhav year old cricketer mumbai died suffering heart attack field playing local cricket match continued bat team despite chest pain severe discomfort according reports died nearby hospital taken medical examination \n",
      "실제 요약 : yr old mumbai cricketer suffers heart attack while playing dies \n",
      "예측 요약 :  fan dies after being hit by football match in mumbai\n",
      "\n",
      "\n",
      "원문 : world trade organization member countries agreed discuss new commerce framework member countries including india decided keep think time right country take multilateral obligations commerce rules government official reportedly said announcement start negotiations made world economic forum \n",
      "실제 요약 : india keeps off wto negotiations on new commerce \n",
      "예측 요약 :  india to invest in india in\n",
      "\n",
      "\n",
      "원문 : union finance ministry given principle approval proposed metro rail projects indore bhopal kanpur agra delhi estimated cost projects lakh crore officials said three corridors phase four delhi metro approved estimated cost crore two kanpur metro corridors approved crore \n",
      "실제 요약 : finance ministry approves metro rail projects in cities \n",
      "예측 요약 :  cabinet approves crore for urban mumbai metro\n",
      "\n",
      "\n",
      "원문 : olympic silver medalist pv sindhu led member strong indian contingent parade nations opening ceremony commonwealth games gold coast australia wednesday athletes countries territories compete gold medals games india finished fifth commonwealth games gold medals \n",
      "실제 요약 : sindhu leads indian at parade of nations at cwg \n",
      "예측 요약 :  pv sindhu to host at cwg medal for st time in cwg\n",
      "\n",
      "\n",
      "원문 : actress politician hema malini speaking kathua unnao rape cases said death penalty proven guilty bail pardon juveniles included rapes added national strong support media animals spare even babies toddlers \n",
      "실제 요약 : death penalty should be for rape hema malini \n",
      "예측 요약 :  rape accused of rape accused bishop\n",
      "\n",
      "\n",
      "원문 : producer boney kapoor said script sequel film entry almost ready approach salman khan added salman fantastic guy work sequel story written keeping mind cannot explore possibilities actors added boney \n",
      "실제 요약 : will approach salman khan for no entry sequel boney kapoor \n",
      "예측 요약 :  cannot be given to play in padmavati shahid kapoor\n",
      "\n",
      "\n",
      "원문 : least seven people killed injured bus skidded road rolled hill himachal pradesh sunday cause accident yet ascertained deputy commissioner lalit jain said people area began rescue operations even authorities reached spot reports said \n",
      "실제 요약 : killed injured after bus rolls down hill in himachal \n",
      "예측 요약 :  killed as bus falls into river in tamil nadu\n",
      "\n",
      "\n",
      "원문 : confirming funding warren buffett led berkshire hathaway paytm founder ceo vijay shekhar sharma said one meeting two phone calls later deal done sharma revealed meeting involved conversation without paper documents presentation could pick money offered berkshire wanted invest accepted added \n",
      "실제 요약 : meeting calls deal was done paytm ceo on berkshire funding \n",
      "예측 요약 :  it is not allowed to take money back paytm ceo\n",
      "\n",
      "\n",
      "원문 : talking compared deepika padukone actress jacqueline fernandez said take comparisons seriously jacqueline seen opposite salman khan race starred deepika race one brings comes play certain character added jacqueline \n",
      "실제 요약 : do not take comparisons too seriously jacqueline fernandez \n",
      "예측 요약 :  deepika is the most choice for me deepika\n",
      "\n",
      "\n",
      "원문 : move towards environment friendly energy storage australia based researchers created world first proton battery uses carbon water instead lithium researchers hope small scale prototype zero carbon emissions could made commercially available within years compete existing lithium ion batteries including tesla \n",
      "실제 요약 : world st battery made has no \n",
      "예측 요약 :  what are the most used used to monitor\n",
      "\n",
      "\n",
      "원문 : thieves caught cctv cameras stealing valuables worth nearly crore shiva temple haryana panchkula district reports said priests claimed thieves broken open locks temple added lakhs rupees given offering deposited bank two days ago valuables left complex \n",
      "실제 요약 : crore theft at shiva temple in haryana caught on camera \n",
      "예측 요약 :  thieves steal cr worth lakh stolen from temple in mp\n",
      "\n",
      "\n",
      "원문 : highlighting businesses try earn goodwill succeed commerce minister suresh prabhu said entrepreneurs must come business idea business opportunity earn goodwill time addressing startup community prabhu added india future lies startups \n",
      "실제 요약 : startups must do biz earn goodwill at same time prabhu \n",
      "예측 요약 :  india is an indian startups with indian startups\n",
      "\n",
      "\n",
      "원문 : steve smith received one test ban admitted australia deliberately conspired cheat third test south africa cameron bancroft caught rubbing ball yellow tape coach darren lehmann talked th man allegedly told bancroft hide bancroft seen putting material trousers \n",
      "실제 요약 : watch the incident for which steve smith received test ban \n",
      "예측 요약 :  smith banned for ashes tests on australia\n",
      "\n",
      "\n",
      "원문 : asked ceo vishal sikka would turn back infosys failing retain high profile executives co chairman ravi venkatesan said hopeful sikka would deliver results think leaving company commenting recent exits said emotional person every time good employee leaves feel bad \n",
      "실제 요약 : sikka will not think of leaving infosys co chairman \n",
      "예측 요약 :  infosys will not be murthy infosys ceo\n",
      "\n",
      "\n",
      "원문 : actor matthew lewis known portraying harry potter franchise announced marriage girlfriend angela jones sharing picture angela tweeted miss arctic monkeys la performing italy time wife made get married instead \n",
      "실제 요약 : actor from harry potter marries girlfriend \n",
      "예측 요약 :  actress gets engaged to slam obama concert\n",
      "\n",
      "\n",
      "원문 : israeli crowd control bomb smells like raw sewage bodies failed tests kashmir locals managed tolerate smell without much difficulty maybe indians higher threshold anonymous high level officials said reported crpf wanted test samples security force refused \n",
      "실제 요약 : israeli bomb fails tests to control crowd in kashmir \n",
      "예측 요약 :  us troops to be held in kabul blast reports\n",
      "\n",
      "\n",
      "원문 : uttar pradesh ats officer said arrested drdo employee nishant aggarwal despite engaged highly sensitive work casual internet made easy target nishant worked nuclear capable brahmos missile systems touch suspected pakistani isi operatives two facebook accounts neha sharma pooja ranjan official added \n",
      "실제 요약 : drdo employee was on internet became easy target police \n",
      "예측 요약 :  mp claims it is not to be held for war on fb\n",
      "\n",
      "\n",
      "원문 : hyderabad police thursday issued orders extending ban begging city two months telangana prisons department also announced reward providing information location beggars city order first issued november two months citing danger safety vehicular traffic general public \n",
      "실제 요약 : ban on begging in hyderabad extended for two months \n",
      "예측 요약 :  mumbai police to open public for public\n",
      "\n",
      "\n",
      "원문 : pm narendra modi visited temples nepal saturday congress leader ashok gehlot alleged move aimed influencing karnataka voters model code conduct karnataka pm modi planned pray temples nepal instead influence voters good trend democracy said \n",
      "실제 요약 : pm visited nepal temples to influence karnataka voters cong \n",
      "예측 요약 :  pm modi to cong mp to open in parliament\n",
      "\n",
      "\n",
      "원문 : dilip bjp mla candidate upcoming madhya pradesh assembly elections greeted garland shoes state video incident shows man suddenly putting garland around neck following mla supporters beat man man apparently wearing bjp cap \n",
      "실제 요약 : man greets bjp mla with shoe garland in mp gets beaten up \n",
      "예측 요약 :  bjp mla caught with bjp mla in up in up\n",
      "\n",
      "\n",
      "원문 : united airlines passengers tickets wider profit margin offering five days advance airline allow passengers sign potential rewards worth willing change flight little united popular seats using new technology flex schedule program \n",
      "실제 요약 : united airlines to booked seats for higher prices \n",
      "예측 요약 :  united airlines to pay crore for over crore\n",
      "\n",
      "\n",
      "원문 : group kashmiri local cricketers detained wednesday video clip surfaced social media showing wearing pakistani team jersey neighbouring country national anthem played background according reports video cricket match two teams one representing pakistan india \n",
      "실제 요약 : kashmiri detained for wearing pak jersey in match \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  arrested for wearing pro pak cricket match in\n",
      "\n",
      "\n",
      "원문 : spanish police seized kg cocaine hidden inside fire resistant bricks part two year investigation international drug smuggling operation run person identified grandmother estimated value cocaine million police also seized buildings vehicles raids \n",
      "실제 요약 : kg cocaine worth crore seized in spain \n",
      "예측 요약 :  kg of drugs seized in gujarat seized in gujarat\n",
      "\n",
      "\n",
      "원문 : release date saif ali khan radhika apte chitrangda singh starrer announced october film also star rohan mehra son late actor vinod mehra directed chawla film set mumbai revolves around world stock trading \n",
      "실제 요약 : release date of saif radhika apte announced \n",
      "예측 요약 :  release date of saif ali khan announced\n",
      "\n",
      "\n",
      "원문 : prime minister narendra modi responded congress vice president rahul gandhi vikas gone mad remark gujarat slogan vikas gujarat congress ran campaign vikas che slamming bjp promise development gujarat pm modi said rally chant hun vikas hun gujarat \n",
      "실제 요약 : pm modi replies to rahul vikas gone mad says am vikas \n",
      "예측 요약 :  pm modi does not know why he is gujarat cm\n",
      "\n",
      "\n",
      "원문 : international monetary fund tuesday growth rate india year projections come true india would surpass china percentage points china world fastest growing major economy india clocked growth rate \n",
      "실제 요약 : india may cross china as fastest growing economy in imf \n",
      "예측 요약 :  india gdp growth at the world bank of\n",
      "\n",
      "\n",
      "원문 : ahmed omar saeed sheikh portrayed rajkummar rao omerta british terrorist pakistani descent member militant outfits including jaish mohammed al qaeda omar kidnapped four foreigners secure kashmiri separatists release also masterminded murder wall street journalist sentenced death \n",
      "실제 요약 : who is omar saeed the terrorist rao plays in omerta \n",
      "예측 요약 :  pakistan army chief resigns over terror attack on fb\n",
      "\n",
      "\n",
      "원문 : year old indian schoolgirl adelaide play football pacific school games drowned beach city schoolgirl whose body pulled water monday accompanied four girls saved time week long international event involved around participants countries \n",
      "실제 요약 : indian drowns after attending school games in aus \n",
      "예측 요약 :  indian cricketer dies after being trapped in bus pool\n",
      "\n",
      "\n",
      "원문 : called idiot former cm omar abdullah india anti terrorist front national president said may idiot anti nationalist like farooq abdullah omar abdullah announced lakh bounty farooq abdullah tongue added omar abdullah seek psychiatric consultation father \n",
      "실제 요약 : am idiot but no anti national chief on farooq bounty \n",
      "예측 요약 :  have been terrorist in the kashmir ex army chief\n",
      "\n",
      "\n",
      "원문 : barcelona first club history player every group world cup least one barcelona player present eight fifa world cup groups tournament teams divided eight groups witnessed lionel messi led argentina register draw iceland opening match \n",
      "실제 요약 : barca st club in history to have player in every wc group \n",
      "예측 요약 :  barcelona lose to barcelona in world cup\n",
      "\n",
      "\n",
      "원문 : centre wednesday told supreme court aap government allegation delhi sits files proposals false added government decisions approved within two three days sc hearing appeals filed delhi government challenging delhi high court verdict holding administrative head delhi \n",
      "실제 요약 : does not sit on files as aap govt alleged centre to sc \n",
      "예측 요약 :  sc seeks centre on centre in delhi over special status\n",
      "\n",
      "\n",
      "원문 : us president donald trump wanted syrian president bashar al assad assassinated last year book written reporter bob claimed book states trump request ignored defense secretary james mattis commenting book trump said another bad book adding quotes book made frauds \n",
      "실제 요약 : trump wanted syrian president assad killed new book claims \n",
      "예측 요약 :  trump calls trump for his first ever white house reports\n",
      "\n",
      "\n",
      "원문 : ias officer pradeep transferred times career spanning years retired wednesday without received salary past six months last posting haryana land use board filed rti application found department exist \n",
      "실제 요약 : ias officer transferred times retires without month pay \n",
      "예측 요약 :  former ias officer who quit himself in yrs\n",
      "\n",
      "\n",
      "원문 : actress shilpa shetty turned friday took instagram share birthday celebration pictures family captioned need family birthday pictures included handmade birthday card six year old son raj kundra thanked husband son fans instagram \n",
      "실제 요약 : all you need is family shilpa shetty on her rd birthday \n",
      "예측 요약 :  happy birthday my husband shilpa wishes shilpa on birthday\n",
      "\n",
      "\n",
      "원문 : american author george man prize lincoln book year old first full length novel based real event wherein president abraham lincoln visited cemetery son buried fiction way making us see truth sanders said \n",
      "실제 요약 : wins man prize for in the \n",
      "예측 요약 :  man who won the ramp in the year award\n",
      "\n",
      "\n",
      "원문 : motel scotland given pink high visibility vests protection cross road house owner said couple like go wee path sometimes across road thought would keep safe put vests wanderers \n",
      "실제 요약 : wear pink to cross the road \n",
      "예측 요약 :  italian village to get its first\n",
      "\n",
      "\n",
      "원문 : user claimed amazon digital assistant alexa powered smart speaker scared saying every time close eyes see people dying without activation user asked repeat statement alexa said understand last year alexa alerted new mexico police hearing owner threatening girlfriend \n",
      "실제 요약 : amazon alexa user says all see is people dying \n",
      "예측 요약 :  amazon makes smart challenge to user\n",
      "\n",
      "\n",
      "원문 : cricketer name gets featured honours board lord scoring century taking five wickets innings picking ten wickets match batting honours board features nine indian batsmen including rahul dravid ajinkya rahane ajit agarkar sourav ganguly sachin tendulkar featured board \n",
      "실제 요약 : how does player get featured on the lord honours board \n",
      "예측 요약 :  ashwin first indian to take wickets in test cricket\n",
      "\n",
      "\n",
      "원문 : educating cricketers appropriate field conduct part icc improved guidelines prevent sexual harassment bullying children vulnerable adults ambit world body stated saturday icc event behaviour welfare policy also introduced immediate effect icc official statement read \n",
      "실제 요약 : icc to educate players on sexual harassment off field conduct \n",
      "예측 요약 :  prez kovind to be part of sexual abuse of women\n",
      "\n",
      "\n",
      "원문 : indian drug majors lupin sun pharma pharmaceuticals recalling various drugs us market presence particulate matter led recall lupin sun pharma mumbai based pharmaceuticals recalling product defective delivery system \n",
      "실제 요약 : india lupin sun pharma recall products in us \n",
      "예측 요약 :  us recalls case against drug stealing\n",
      "\n",
      "\n",
      "원문 : brazil based firm developed plastic containers change colours changing levels contents sign possible expiry first prototype made technology still tested ensure accurate detection considering factors levels containers would commercial years said company \n",
      "실제 요약 : firm makes colour changing that signals food \n",
      "예측 요약 :  smart to use pizza to make its future\n",
      "\n",
      "\n",
      "원문 : singapore based nupur slammed travel booking platform denied accommodation hyderabad hotel despite pre booked room single lady questioned asked gender filter hotels also tagged brand ambassador deepika padukone twitter urging startup change policies \n",
      "실제 요약 : woman slams after hotel denies room as she is single \n",
      "예측 요약 :  mcdonald slammed for asking to pay for women\n",
      "\n",
      "\n",
      "원문 : aap leader raghav chadha facing criminal case retweeting delhi cm kejriwal tweets union minister arun jaitley told delhi high court retweet constitute criminal defamation jaitley filed defamation case six aap leaders seeking crore damages allegedly accusing corruption social media platforms \n",
      "실제 요약 : does not cause defamation aap leader to delhi hc \n",
      "예측 요약 :  kejriwal denies allegations of ex media chief\n",
      "\n",
      "\n",
      "원문 : indian army monday said pakistan army hiring civilians snoop indian posts latter alleged india carried unprovoked firing targeted civilians along border civilians repeatedly used gain information locations providing guides terrorists crossing loc lt general ak bhatt told pakistani counterpart \n",
      "실제 요약 : pak hiring civilians to snoop on indian posts indian army \n",
      "예측 요약 :  pakistan army to ceasefire at loc in pakistan\n",
      "\n",
      "\n",
      "원문 : local court maharashtra issued non bailable warrant andhra pradesh cm chandrababu naidu others case violated prohibitory orders protest irrigation project claimed project would affect water supply people andhra court ordered accused presented september \n",
      "실제 요약 : arrest warrant issued against andhra cm in protest case \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  andhra cm seeks probe on ex cm andhra cm arrest\n",
      "\n",
      "\n",
      "원문 : many initial public offerings hit indian stock market year raising billion according report report said represents increase deal numbers compared notably largest ipo proceeds region general insurance corporation india worth billion \n",
      "실제 요약 : firms raised billion through in report \n",
      "예측 요약 :  misconduct of bn market value bn market cap hit by\n",
      "\n",
      "\n",
      "원문 : pm narendra modi tuesday laid foundation stone thane kalyan metro mira metro corridors maharashtra pm modi also launched city industrial development corporation maharashtra mass housing scheme offers affordable homes pradhan mantri awas yojana mumbai thane helped nation realise dreams pm said \n",
      "실제 요약 : pm lays foundation stone of metro in maharashtra \n",
      "예측 요약 :  pm modi to launch mumbai metro train for mumbai\n",
      "\n",
      "\n",
      "원문 : islamic state monday claimed responsibility attack police convoy egypt sinai peninsula attack killed police officials left seven others injured militants detonated improvised explosive device destroyed four armoured vehicles signal vehicle officials said \n",
      "실제 요약 : is claims responsibility for police convoy attack in egypt \n",
      "예측 요약 :  islamic state claims responsibility for attack on islamic state\n",
      "\n",
      "\n",
      "원문 : sarabhai vs sarabhai actor sumeet raghavan said india like living sex starved nation said following incident man inside bmw car started masturbating front actor wife case years ago even parents children cases came light added sumeet \n",
      "실제 요약 : we live in sex starved nation says tv actor sumeet \n",
      "예측 요약 :  was told to my kids was told my life was molested actress\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e490ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29bbbdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   50  1775  3676    74   155   110   368     7   518   182    15 13089\n",
      "  1384  1392  1381   331    15     6   856  7540  7334  7393  6977 15374\n",
      " 19384  6168  1816   243  6055   334  4517   404   218   403     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "# 테스트 데이터 다운로드 \n",
    "#text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
    "# 데이터 출력 \n",
    "#print('Summary:')\n",
    "#print(summarize(text, words=100))\n",
    "\n",
    "print(encoder_input_test[50])\n",
    "#print(\"원문 :\", seq2text(encoder_input_test[50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee5574",
   "metadata": {},
   "source": [
    "## 회고\n",
    "### 배운점\n",
    "텍스트를 요약하기 위해 어텐션 메커니즘을 이용하여 추상적 추출을 하고 추출적 추출을 하는 방법을 배웠습니다. \n",
    "### 아쉬운점\n",
    "완벽히 이해하지 못한것이 아쉽다.\n",
    "### 느낀점\n",
    "아직까지는 인코더 디코더 모델의 설계를 이해하지 못한 부분이 많고 다양한 공부를 통해 보충이 필요할것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397d828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
