{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b705cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4317029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "# text , headlines\n",
    "data.sample(10)\n",
    "# data.shape // (98401, 2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b159e0",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b004a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "data 중 null 취합 확인\n",
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n",
      "남은 전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "#중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "\n",
    "## 중복확인\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "## null 값 확인 \n",
    "print('data 중 null 취합 확인')\n",
    "print(data.isnull().sum())\n",
    "\n",
    "## text 열 기준 중복제거 \n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "\n",
    "print('남은 전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfbdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정규화와 불용어 제거\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8270164",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "headlines: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 정상적으로 전처리 되는지 테스트 \n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5281f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n",
      "headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "# text 데이터 전처리 \n",
    "clean_text = []\n",
    "for sentence in data[\"text\"]:\n",
    "    clean_text.append(preprocess_sentence(sentence, remove_stopwords=True))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])\n",
    "\n",
    "# headlines 데이터 전처리 단 요약데이터는 짧으므로 불용어 제거 안함 remove_stopwords=False\n",
    "clean_headlines = []\n",
    "for sentence in data[\"headlines\"]:\n",
    "    clean_headlines.append(preprocess_sentence(sentence, remove_stopwords=False))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b059cb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# 데이터 이상하게 들어 방지 임시데이터 생성\n",
    "tmp_clean_text = clean_text.copy()\n",
    "tmp_clean_headlines = clean_headlines.copy()\n",
    "# 전처리 후 빈값 데이터가 생겼는지 확인 \n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.isnull().sum()\n",
    "\n",
    "# 생겼다면 제거 \n",
    "#data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58757ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    }
   ],
   "source": [
    "# 길이분포 확인\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b28825f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360 => 98343\n"
     ]
    }
   ],
   "source": [
    "# 적정 최대길이 지정 \n",
    "text_max_len = 50\n",
    "headlines_max_len = 15\n",
    "\n",
    "# data에서 로우를 공백기준으로 자른경우 길이가 최대길이보다 작거나 같은 데이터만 포함\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "\n",
    "print(f'전체 샘플수 : {len(tmp_clean_text)} => {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e738c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 데이터에 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "\n",
    "#Numpy 타입으로 저장\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6952291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정수화 \n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "# 샘플 순서 재정의\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "# 테스트 , 훈련데이터 분리 0.2 를 곱해서 8:2 기준으로 분리\n",
    "n_of_val = int(len(encoder_input)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af07c3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78675\n",
      "훈련 레이블의 개수 : 78675\n",
      "테스트 데이터의 개수 : 19668\n",
      "테스트 레이블의 개수 : 19668\n"
     ]
    }
   ],
   "source": [
    "# 분리 데이터 확인 \n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f59ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year old man arrested allegedly molesting woman attacking friend knife goa said police accused identified agnelo tried forcefully hug woman police said rescued following male friend went confront elderly man attacked knife\n"
     ]
    }
   ],
   "source": [
    "# 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 변경 \n",
    "print(encoder_input_train[0])\n",
    "# Keras의 토크나이저를 사용\n",
    "# src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "# src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf4c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_train \n",
      "단어 집합(vocabulary)의 크기 : 69506\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47322\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22184\n",
      "단어 집합에서 희귀 단어의 비율: 68.0833309354588\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.480428540911609\n",
      "decoder_input_train \n",
      "단어 집합(vocabulary)의 크기 : 30063\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20542\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9521\n",
      "단어 집합에서 희귀 단어의 비율: 68.32984066793067\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.313068393554772\n"
     ]
    }
   ],
   "source": [
    "# 집합크기 제한전 적정값을 찾기위해 값 추출 함수화 \n",
    "def get_data_index_per(threshold = 7,data = False):\n",
    "    src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "    src_tokenizer.fit_on_texts(data) # 입력된 데이터로부터 단어 집합 생성\n",
    "    threshold = 7\n",
    "    total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in src_tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    \n",
    "print(\"encoder_input_train \")\n",
    "get_data_index_per(7,encoder_input_train)\n",
    "\n",
    "print(\"decoder_input_train \")\n",
    "get_data_index_per(6,decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c44d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input  [[3, 13, 37, 89, 53, 5137, 62, 3855, 784, 3952, 1043, 1, 9, 42, 1169, 646, 7999, 4726, 62, 9, 1, 1383, 96, 1253, 784, 321, 13370, 5054, 37, 1038, 3952], [8282, 271, 7, 991, 19, 196, 504, 101, 1463, 4117, 86, 136, 264, 41, 2100, 5544, 192, 1625, 6464, 4058, 234, 131, 14814, 2544, 8000, 928, 55, 87, 13833, 379, 1533, 29, 116, 600], [11, 2685, 6465, 18412, 3058, 15387, 676, 2280, 10727, 254, 377, 5487, 24, 113, 920, 4654, 18412, 2435, 1519, 377, 5488, 113, 1031, 4575, 600, 203, 676, 576, 676, 486, 1058, 1, 18412]]\n",
      "decoder input  [[1, 41, 26, 20, 85, 5, 2340, 39, 4, 453], [1, 5408, 568, 3, 3914, 4, 227, 34, 30, 233, 348, 4, 60], [1, 28, 1283, 1818, 14, 52, 602, 182, 3, 1189, 4278], [1, 1240, 630, 42, 312, 4, 652, 6, 501, 38, 202, 36], [1, 27, 122, 653, 242, 6, 431, 4, 124, 5017]]\n",
      "decoder target  [[41, 26, 20, 85, 5, 2340, 39, 4, 453, 2], [5408, 568, 3, 3914, 4, 227, 34, 30, 233, 348, 4, 60, 2], [28, 1283, 1818, 14, 52, 602, 182, 3, 1189, 4278, 2], [1240, 630, 42, 312, 4, 652, 6, 501, 38, 202, 36, 2], [27, 122, 653, 242, 6, 431, 4, 124, 5017, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 제외 집합크기 약 20000 , 9500 으로 텍스트를 정수로 변환작업 \n",
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print('encoder input ',encoder_input_train[:3])\n",
    "\n",
    "tar_vocab = 9500\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('decoder input ',decoder_input_train[:5])\n",
    "print('decoder target ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c7912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78675\n",
      "훈련 레이블의 개수 : 78675\n",
      "테스트 데이터의 개수 : 19668\n",
      "테스트 레이블의 개수 : 19668\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 과정에서 공백이되어버린 sos , eos 가 남아있기때문에 1 값을 찾아 삭제 \n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d903be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3   13   37 ...    0    0    0]\n",
      " [8282  271    7 ...    0    0    0]\n",
      " [  11 2685 6465 ...    0    0    0]\n",
      " ...\n",
      " [3516  874 1144 ...    0    0    0]\n",
      " [ 277 1571 2084 ...    0    0    0]\n",
      " [  75    9   68 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 길이맞추기위해서 post 기준으로 padding 추가 \n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print(encoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b9811",
   "metadata": {},
   "source": [
    "### Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa67c9a",
   "metadata": {},
   "source": [
    "인코딩 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5ecaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55244a09",
   "metadata": {},
   "source": [
    "디코딩 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e29bae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aeea61",
   "metadata": {},
   "source": [
    "출력층 ( 어텐션 메커니즘 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89bc2d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1216000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9500)   4873500     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,488,860\n",
      "Trainable params: 10,488,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "# decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "# decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "# 모델 정의\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "# model.summary()\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_output3])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd143ee",
   "metadata": {},
   "source": [
    "모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb3cb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 42s 113ms/step - loss: 4.5408 - val_loss: 4.1861\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 34s 112ms/step - loss: 4.0239 - val_loss: 3.8387\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 35s 115ms/step - loss: 3.7516 - val_loss: 3.6542\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 37s 119ms/step - loss: 3.5470 - val_loss: 3.5061\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.3812 - val_loss: 3.3905\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 3.2415 - val_loss: 3.2933\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.1256 - val_loss: 3.2199\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 3.0245 - val_loss: 3.1671\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.9356 - val_loss: 3.1182\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.8547 - val_loss: 3.0762\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.7822 - val_loss: 3.0472\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.7150 - val_loss: 3.0220\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.6578 - val_loss: 3.0004\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.6044 - val_loss: 2.9831\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.5538 - val_loss: 2.9631\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.5066 - val_loss: 2.9566\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.4624 - val_loss: 2.9452\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.4218 - val_loss: 2.9408\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 36s 117ms/step - loss: 2.3823 - val_loss: 2.9331\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.3464 - val_loss: 2.9281\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.3132 - val_loss: 2.9279\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.2808 - val_loss: 2.9192\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.2486 - val_loss: 2.9175\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.2192 - val_loss: 2.9173\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.1918 - val_loss: 2.9152\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.1660 - val_loss: 2.9131\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.1418 - val_loss: 2.9157\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.1174 - val_loss: 2.9123\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.0942 - val_loss: 2.9189\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 36s 118ms/step - loss: 2.0723 - val_loss: 2.9192\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b89bec",
   "metadata": {},
   "source": [
    "훈련된 모델 로스값 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1547d432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695ae34",
   "metadata": {},
   "source": [
    "### Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba496d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제데이터 복원을위한 데이터셋 \n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output3, state_h3, state_c3])\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790a258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99cbb3",
   "metadata": {},
   "source": [
    "단어 시퀀스를 완성을 위한 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1091b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a954f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i == 2): # End token\n",
    "            break\n",
    "        if (i!=0 and i != 1): # Exclude padding and start token\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b34e5c",
   "metadata": {},
   "source": [
    "데이터 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b8a7f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : arjun tendulkar seen ground staff duty lord rain stopped play second day india england test arjun part mcc young cricketers training lord earlier seen bowling indian batsmen nets sachin also ground yesterday invited ring five minute bell \n",
      "실제 요약 : arjun tendulkar does ground duty at lord as rain stops play \n",
      "예측 요약 :  sachin tendulkar shares video of him helmet\n",
      "\n",
      "\n",
      "원문 : ceo encrypted messaging app telegram pavel said platform blocked channels october terrorist links violence promotion violence form banned added telegram faced criticism past claims terrorists criminals used encrypted communication \n",
      "실제 요약 : terrorist channels blocked in one month telegram ceo \n",
      "예측 요약 :  terror groups can be used to india myanmar ceo\n",
      "\n",
      "\n",
      "원문 : threat us sanctions stop russia pursuing future defence deals india russian ambassador india said added india russia could sign deals assault rifles within two three months us law imposes sanctions countries military trade russia \n",
      "실제 요약 : us sanctions will not stop future deals with india russia \n",
      "예측 요약 :  us to russia ties with us on russia sanctions\n",
      "\n",
      "\n",
      "원문 : niti aayog vice chairman rajiv kumar accepted challenge former finance minister chidambaram debate revised gdp data released wednesday new back series data showed economic growth current nda regime better upa rule chidambaram termed gdp data revision job niti aayog \n",
      "실제 요약 : niti aayog vc accepts chidambaram challenge on revised gdp data \n",
      "예측 요약 :  economic patel takes dig at indian gdp data by india\n",
      "\n",
      "\n",
      "원문 : iit delhi alumnus jain iit kanpur alumnus sahil co founded gurugram based darwin labs arrested links crore bitcoin scam scam founder amit bhardwaj recently arrested bangkok duo allegedly part conspiracy built payment gateway used bhardwaj \n",
      "실제 요약 : iitian startup founders arrested in crore bitcoin scam \n",
      "예측 요약 :  iit ed ceo arrested for cheating of his own board\n",
      "\n",
      "\n",
      "원문 : arsenal scored two goals within seven minutes second half register comeback win premier league saturday arsenal manager arsene wenger became second manager sir alex ferguson manage premier league matches meanwhile french forward anthony martial late goal helped manchester united beat tottenham old trafford \n",
      "실제 요약 : arsenal win wenger th pl match man utd beat \n",
      "예측 요약 :  man city beat chelsea to register th straight win\n",
      "\n",
      "\n",
      "원문 : india plans establish approximately new airports cost lakh crore within next years minister state civil aviation jayant sinha said constructed locations facility rest second airports expansion existing sinha added \n",
      "실제 요약 : india to get new airports in the next years \n",
      "예측 요약 :  india to invest crore in mumbai\n",
      "\n",
      "\n",
      "원문 : rajkummar rao starring nushrat hansal mehta next film khan produced ajay devgn luv ranjan ankur garg sharing news rajkummar tweeted excited collaborate dearest hansal sir looking forward fun association rajkummar earlier collaborated hansal omerta aligarh city lights shahid \n",
      "실제 요약 : rajkummar rao to star with in hansal khan \n",
      "예측 요약 :  rajkummar rao to star in upcoming film\n",
      "\n",
      "\n",
      "원문 : bits pilani presented th edition technical fest march march festival hosted personalities simon salman khurshid manu joseph zakir khan year also held events like bsf exhibition hyperloop india exhibit literature festival democracy indian jam project \n",
      "실제 요약 : bits pilani hosts th edition of technical fest \n",
      "예측 요약 :  iit bombay to host new year kumar from super\n",
      "\n",
      "\n",
      "원문 : man wife mumbai arrested allegedly neighbour rakesh shinde death shinde asked wife mobile number man earlier got altercation neighbour following shinde came house abused wife couple strangled fit rage \n",
      "실제 요약 : couple held for killing neighbour for asking woman number \n",
      "예측 요약 :  man held for wife for years for wife wife\n",
      "\n",
      "\n",
      "원문 : following sbi new rules including charges certain transactions effective april customers taken social media call transaction day april calling protests april april bank remove charges customers six banks merged sbi also follow rules \n",
      "실제 요약 : customers to boycott sbi over new charges \n",
      "예측 요약 :  sbi to shut down over note ban on\n",
      "\n",
      "\n",
      "원문 : woman driver rescued unhurt california accidentally hit car accelerator instead brake went hanging fourth floor multi level parking removing car firefighters secured cables keep falling tow truck pulled car back parking \n",
      "실제 요약 : car hangs from parking th floor after driver hits accelerator \n",
      "예측 요약 :  woman jumps off moving car to save woman dies\n",
      "\n",
      "\n",
      "원문 : cbi booked oriental bank commerce employee four firs related alleged cheating kisan credit cards causing crore loss bank lal meena special assistant posted rajasthan booked alleged cheating forgery bank identified loan accounts meena committed cheating \n",
      "실제 요약 : cbi books obc employee for crore loss to the bank \n",
      "예측 요약 :  cbi books pnb officials for cheating sbi of cr\n",
      "\n",
      "\n",
      "원문 : andhra pradesh cm chandrababu naidu announced resignation two tdp union ministers west bengal cm mamata banerjee asked bjp could hear voices dissent allies dare aim bengal bengal give befitting reply added recently tmc chief supported telangana cm kc rao call third front \n",
      "실제 요약 : cannot bjp hear mamata after tdp ministers resign \n",
      "예측 요약 :  andhra cm calls for andhra assembly elections\n",
      "\n",
      "\n",
      "원문 : many bjp mps mlas criminal charges related kidnapping filed highest political party india according association democratic reforms report congress rjd joint second six many lawmakers declared serious criminal charges report added \n",
      "실제 요약 : highest number of kidnapping accused lawmakers from bjp adr \n",
      "예측 요약 :  bjp mps face action against bjp for corruption report\n",
      "\n",
      "\n",
      "원문 : gangster abu salem sent legal notice makers sanjay dutt biopic sanju stating shows incorrect information alleged involvement supplying weapons dutt scene ranbir kapoor portrays dutt police salem claimed never met dutt give arms ammunition \n",
      "실제 요약 : abu salem sends notice to sanju makers claims he never met dutt \n",
      "예측 요약 :  dutt sends notice to dutt over sanju release in sanju\n",
      "\n",
      "\n",
      "원문 : according reports actress aishwarya rai star opposite actor anil kapoor years upcoming film film titled fanney khan produced rakeysh omprakash mehra directed debutant atul manjrekar musical comedy said inspired oscar nominated everybody famous \n",
      "실제 요약 : aishwarya to star with anil in film after years report \n",
      "예측 요약 :  aishwarya rai to star in fanney khan film reports\n",
      "\n",
      "\n",
      "원문 : us president donald trump warned north korean leader kim jong un suffer libyan dictator muammar gaddafi fate make deal nuclear program trump warning follows national security advisor john bolton idea north korea libya style denuclearisation however trump interpreted libya model nato intervention libya led gaddafi murder \n",
      "실제 요약 : make deal or suffer fate trump warns kim jong un \n",
      "예측 요약 :  kim jong un chief could be to be the trump\n",
      "\n",
      "\n",
      "원문 : actor zac revealed saved fire co actor hugh jackman sets film greatest added know burning building later exploded night said jokingly every girl dream saved jackman burning building \n",
      "실제 요약 : hugh jackman saved me from burning building on film set \n",
      "예측 요약 :  was not an actor in the sets of my life in my career\n",
      "\n",
      "\n",
      "원문 : congress president rahul gandhi denied party involvement anti sikh riots former finance minister chidambaram said cannot held responsible riots took place aged chidambaram added ex pm manmohan singh apologised parliament riots took place congress government following pm indira gandhi assassination \n",
      "실제 요약 : cannot hold rahul responsible for he was ex fm \n",
      "예측 요약 :  rahul gandhi is anti corruption congress\n",
      "\n",
      "\n",
      "원문 : microblogging site twitter tuesday went several countries around world including us uk japan service outage affected desktop mobile users however services social media platform went april well restored within hour \n",
      "실제 요약 : site twitter faces global outage \n",
      "예측 요약 :  twitter user demand his name to hackers\n",
      "\n",
      "\n",
      "원문 : international olympic committee paid around lakh training north korea athletes participated winter olympics south korea spent around crore north korean leader kim jong un sister visit games amount spent athletes training \n",
      "실제 요약 : korea envoys visit cost more than athletes training \n",
      "예측 요약 :  korean artist granted lakh for us flood victims\n",
      "\n",
      "\n",
      "원문 : thirteen suspected islamic state fighters india among militants killed us military dropped powerful non nuclear bomb afghanistan according report however security sources delhi refused confirm indian killed attack reportedly least two dozen indians joined isis afghanistan \n",
      "실제 요약 : isis fighters from india killed in us strike report \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  al qaeda killed in afghanistan in afghanistan\n",
      "\n",
      "\n",
      "원문 : talking ongoing controversy film padmaavat deepika padukone said endorsing jauhar must see scene context period shown said scene powerful adding feel like wrong deepika said difficult scene perform \n",
      "실제 요약 : we are not endorsing jauhar deepika padukone on padmaavat \n",
      "예측 요약 :  deepika is the most thing deepika on padmavati row\n",
      "\n",
      "\n",
      "원문 : india drugs recalling batches blood pressure heart medicine us amid wider probe cancer risks associated drug found using similar manufacturing process china pharmaceutical drug made found contain human \n",
      "실제 요약 : indian firm pulls heart drug from us amid cancer risk probes \n",
      "예측 요약 :  india to study cancer after cancer\n",
      "\n",
      "\n",
      "원문 : indian team trailing runs reduced end second day fifth test oval saturday earlier day ravindra jadeja finished figures helping india dismiss england jos buttler scoring jasprit bumrah ishant sharma picked three wickets \n",
      "실제 요약 : india trail by runs at the end of day of th test \n",
      "예측 요약 :  india end day at home for the first time in years\n",
      "\n",
      "\n",
      "원문 : sharing picture class actress aishwarya rai bachchan wrote grade age aaradhya shared another picture childhood captioned times aishwarya recently joined instagram ahead appearance year cannes film festival aaradhya bachchan turn november aishwarya first child abhishek bachchan \n",
      "실제 요약 : same age as daughter aaradhya aishwarya on her class pic \n",
      "예측 요약 :  picture of arjun on pic with her daughters\n",
      "\n",
      "\n",
      "원문 : american electric carmaker tesla burning cash rate every hour past months current pace exhaust entire cash august according bloomberg tesla however said enough money meet model production target march end delayed \n",
      "실제 요약 : tesla burning through crore every hour \n",
      "예측 요약 :  tesla lost lakh in tesla report\n",
      "\n",
      "\n",
      "원문 : former pakistan ambassador us husain haqqani said country collapse like soviet union quit losing arms race adding nuclear weapons use haqqani said pakistan needs focus economy education seeks become great power \n",
      "실제 요약 : pak will fall like if it arms race ex envoy \n",
      "예측 요약 :  pak will not take back ex pak envoy after days of pak\n",
      "\n",
      "\n",
      "원문 : real madrid cristiano ronaldo received standing opposition fans scored bicycle kick champions league quarter final first leg juventus tuesday year old back facing goal score th minute six seconds juventus goalkeeper produced flying save deny lucas \n",
      "실제 요약 : ronaldo nets bicycle kick goal opposition fans him \n",
      "예측 요약 :  ronaldo scores as real madrid beat real madrid\n",
      "\n",
      "\n",
      "원문 : two class girls government school madhya pradesh village allegedly made strip two women teachers suspicion stealing classmate money found search police said school however refuted charges levelled girls saying subjected general search \n",
      "실제 요약 : teachers strip search girls on theft charges in mp school \n",
      "예측 요약 :  girls girls made to mp school in mp\n",
      "\n",
      "\n",
      "원문 : french hacker elliot tweeted pm narendra modi saturday asking aadhaar card number leaking trai chief rs sharma personal details sharma tweeted aadhaar card number open challenge prove data safe elliot shared sharma phone number among details besides tweeting change gmail password \n",
      "실제 요약 : hacker asks pm modi for aadhaar no after leaking trai head info \n",
      "예측 요약 :  aadhaar cards not aadhaar cards pm modi\n",
      "\n",
      "\n",
      "원문 : us third fourth largest wireless carriers mobile sprint officially called merger talks claiming unable find mutually terms second time merger talks failed chief executives companies said still see benefits combining indicated talks ended financial terms \n",
      "실제 요약 : mobile sprint call off merger talks for second time \n",
      "예측 요약 :  us to launch its biggest cryptocurrency in us\n",
      "\n",
      "\n",
      "원문 : south korean football team coach shin yong revealed made players swap shirts heard swedish spy present training sessions yong said tactic shirts side final warm matches taking advantage fact find difficult distinguish asians \n",
      "실제 요약 : korea coach made players swap shirts to confuse opponents \n",
      "예측 요약 :  south korean team once called me after years\n",
      "\n",
      "\n",
      "원문 : following reports revealing large scale data scandal facebook said mark sheryl teams working around clock get facts take appropriate action adding understand issue seriousness facebook said entire company deceived committed vigorously enforcing policies protect people information \n",
      "실제 요약 : entire company we were fb on data scandal \n",
      "예측 요약 :  facebook is no one of its biggest facebook coo\n",
      "\n",
      "\n",
      "원문 : actress richa chadha denied rumours dating pink actor angad bedi adding nothing going like richa angad seen together upcoming web series inside edge source previously said met started work together spending time together since \n",
      "실제 요약 : nothing going on richa on rumours of dating angad bedi \n",
      "예측 요약 :  richa chadha is like my friend richa chadha\n",
      "\n",
      "\n",
      "원문 : roll gst indian wedding union minister jayant sinha wednesday said like indian weddings great big party everyone live happily ever sinha said call gst republic instrument simplicity adding tax would help control inflation people india \n",
      "실제 요약 : jayant sinha likens gst launch to happy indian wedding \n",
      "예측 요약 :  gst is like hindi sushil kumar on sushil kumar\n",
      "\n",
      "\n",
      "원문 : national green tribunal directed delhi government delhi pollution control committee ensure religious places east delhi strictly follow prescribed noise pollution norms comes petitioner alleged illegal use loudspeakers places worship adversely impacted health residents \n",
      "실제 요약 : religious places must follow noise pollution norms ngt \n",
      "예측 요약 :  delhi govt bans use of pollution in delhi\n",
      "\n",
      "\n",
      "원문 : man tamil nadu allegedly got drunk set car building two wheelers fire wife stopped talking according police woman stopped speaking unemployed husband past several days refused look job police arrested man examining cctv footage \n",
      "실제 요약 : man sets car building on fire after wife stops talking to him \n",
      "예측 요약 :  man dies after wife his wife his car in delhi\n",
      "\n",
      "\n",
      "원문 : international solar alliance become first treaty based international government organisation based india idea solar alliance countries receive sunshine around days year promoted pm narendra modi aims facilitate deployment solar energy aggregating demand funding technology innovation \n",
      "실제 요약 : becomes first treaty based int body based in india \n",
      "예측 요약 :  india to launch first ever solar eclipse in india\n",
      "\n",
      "\n",
      "원문 : science english added tests classes schools across maharashtra subjects added report revealed class students could read english knew division tests launched aimed assessing basic skills students classes \n",
      "실제 요약 : new added to tests in maha schools \n",
      "예측 요약 :  class results have no toilet in english presidential\n",
      "\n",
      "\n",
      "원문 : denying reports got engaged rumoured boyfriend ranveer singh january vacation maldives deepika padukone said engaged said neha dhupia hosted talk show bffs vogue deepika sister anisha padukone appeared show jokingly added engaged last four years \n",
      "실제 요약 : not engaged to ranveer deepika on rumours of engagement \n",
      "예측 요약 :  ranveer singh is the and he is ranveer singh\n",
      "\n",
      "\n",
      "원문 : newly released footage shows year old united airlines passenger david arguing law enforcement officers forcibly drag overbooked flight heard repeating going threatening file lawsuit united officers say drag replies well drag go \n",
      "실제 요약 : new video shows moments before man dragged off united flight \n",
      "예측 요약 :  united flyer sues united for not paying\n",
      "\n",
      "\n",
      "원문 : actress shraddha kapoor said working actor prabhas upcoming film saaho great opportunity added first time shooting hindi telugu film actors jackie shroff neil nitin mukesh chunky pandey reportedly feature negative roles film \n",
      "실제 요약 : working with prabhas in saaho is great opportunity shraddha \n",
      "예측 요약 :  shraddha to star in film on sets of film with prabhas\n",
      "\n",
      "\n",
      "원문 : law commission chairman justice bs chauhan friday said panel report betting gambling misunderstood clarifying recommended complete ban instead legalising two activities chauhan said listed measures effective regulation case government able implement complete ban betting gambling \n",
      "실제 요약 : report on betting gambling law panel chief \n",
      "예측 요약 :  panel slams bcci for not making non bailable order\n",
      "\n",
      "\n",
      "원문 : world largest efficient lighting programme inaugurated union minister state power coal new renewable energy mines piyush goyal london sunday programme aims increase led uk goyal announced lights indian high commission india house country \n",
      "실제 요약 : piyush goyal over largest event \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  world largest budget to be sold for years\n",
      "\n",
      "\n",
      "원문 : natural history museum switzerland identified century mummy uk foreign secretary boris johnson ancestor basis dna tests identity body found without remained mystery since uk secretary reacted revelation tweeting excited hear late great grand mummy nnn \n",
      "실제 요약 : th century swiss mummy identified as uk secy \n",
      "예측 요약 :  world oldest country to have been world longest\n",
      "\n",
      "\n",
      "원문 : many chickens burnt alive poultry farm uttar pradesh shamli district police said tuesday incident happened electrical wire fell roof shed leading massive fire fire controlled help villagers owner poultry farm said \n",
      "실제 요약 : die after farm catches fire in up \n",
      "예측 요약 :  farmer dies after getting stuck in maharashtra\n",
      "\n",
      "\n",
      "원문 : khaleel ahmed given maiden odi call form inclusion india asia cup squad left arm pacer rajasthan represented india recently concluded series ahmed took seven wickets four matches india series also part india world cup squad \n",
      "실제 요약 : who is ahmed uncapped player selected for asia cup \n",
      "예측 요약 :  india captain named india after series of sa tour\n",
      "\n",
      "\n",
      "원문 : lyricist filmmaker gulzar said need return film direction new generation filmmakers making films better might thoughts earlier films good films gulzar added gulzar last directorial hu tu tu \n",
      "실제 요약 : new generation filmmakers are much ahead of me gulzar \n",
      "예측 요약 :  there is no role in film industry says tabu\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d19bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4a155d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1246   855   162   923   645  1294  1102  2673  1007   278    91    44\n",
      "     2   246    71  1246   109 15712  1134  1451  1031  1102    33   162\n",
      "  1562    11  2868  7746   542     6   923  7047  1775  2841    87  1025\n",
      "  6528     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "# 테스트 데이터 다운로드 \n",
    "#text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
    "# 데이터 출력 \n",
    "#print('Summary:')\n",
    "#print(summarize(text, words=100))\n",
    "\n",
    "print(encoder_input_test[50])\n",
    "#print(\"원문 :\", seq2text(encoder_input_test[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0b256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
